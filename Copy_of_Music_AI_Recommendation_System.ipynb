{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaS5n62ynglq"
      },
      "source": [
        "# 🎵 AI Music Recommendation System - Google Colab\n",
        "\n",
        "This notebook runs the complete Music AI Recommendation System with GPT-OSS-20B and neural networks.\n",
        "\n",
        "## 🚀 Features:\n",
        "- AI-powered music recommendations\n",
        "- GPT-OSS-20B natural language explanations\n",
        "- Spotify integration with OAuth\n",
        "- RLHF preference learning\n",
        "- Interactive Streamlit frontend\n",
        "\n",
        "## 📋 Setup Instructions:\n",
        "1. **Enable GPU**: Runtime > Change runtime type > GPU (T4 or better)\n",
        "2. **Run all cells** in order\n",
        "3. **Get Spotify API credentials** from https://developer.spotify.com/dashboard\n",
        "4. **Update credentials** in the config cell\n",
        "5. **Enjoy your AI music recommendations!**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lhys2d_6nglq"
      },
      "source": [
        "## 🔧 Step 1: Install Dependencies and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tDgW4WT1nglr",
        "outputId": "d7f97cff-812c-4972-e839-7c1a748ec090",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/10.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m8.3/10.0 MB\u001b[0m \u001b[31m250.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m244.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m134.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/510.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m114.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m121.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.4/414.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m117.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m122.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.1/117.1 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m113.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.8/384.8 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.9/284.9 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m949.7/949.7 kB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.8/279.8 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ Dependencies installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "%pip install -q streamlit fastapi uvicorn[standard] pydantic pydantic-settings\n",
        "%pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "%pip install -q transformers vllm scikit-learn numpy pandas\n",
        "%pip install -q spotipy sqlalchemy aiosqlite httpx aiohttp requests\n",
        "%pip install -q jedi>=0.16\n",
        "%pip install -q plotly rich python-dotenv google-colab\n",
        "%pip install -q pyngrok\n",
        "\n",
        "print(\"✅ Dependencies installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hfNyOPhwnglr",
        "outputId": "43dbbe40-2c9f-412e-c26b-64b751e8665f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hack-mvp'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 47 (delta 5), reused 42 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (47/47), 68.86 KiB | 11.48 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n",
            "/content/hack-mvp\n",
            "✅ Repository cloned and directories created!\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/rsm-wew068/hack-mvp.git\n",
        "%cd hack-mvp\n",
        "\n",
        "# Create necessary directories\n",
        "!mkdir -p models data logs\n",
        "\n",
        "print(\"✅ Repository cloned and directories created!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Uo8DVsQ1nglr",
        "outputId": "ccfcbec9-a4ce-4f21-a155-4f0299b38a9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Repository cloned and directories created!\n"
          ]
        }
      ],
      "source": [
        "# Create necessary directories\n",
        "!mkdir -p models data logs\n",
        "\n",
        "print(\"✅ Repository cloned and directories created!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-kTTBrfgnglr",
        "outputId": "cfb7b4f8-4c57-430f-c0ad-779d7b5e5958",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔗 Setting up ngrok for better port forwarding...\n",
            "   You can get a free ngrok authtoken from: https://dashboard.ngrok.com/get-started/your-authtoken\n",
            "   (Optional - the app will work without it, but ngrok provides better URLs)\n",
            "✅ ngrok setup complete!\n"
          ]
        }
      ],
      "source": [
        "# Setup ngrok for Colab port forwarding (alternative method)\n",
        "from pyngrok import ngrok\n",
        "import getpass\n",
        "\n",
        "# Get ngrok authtoken (optional but recommended)\n",
        "print(\"🔗 Setting up ngrok for better port forwarding...\")\n",
        "print(\"   You can get a free ngrok authtoken from: https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "print(\"   (Optional - the app will work without it, but ngrok provides better URLs)\")\n",
        "\n",
        "# Uncomment and add your ngrok authtoken if you have one:\n",
        "ngrok.set_auth_token(\"32QgKuZ26X0TdHnYX6Whl2rg3tI_6UGuUxUD7uJ7ph623sfou\")\n",
        "\n",
        "print(\"✅ ngrok setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rFEzut3rnglr",
        "outputId": "072c764f-3043-421f-90ec-aa2b4ff138f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 GPU detected: NVIDIA L4 (Count: 1)\n",
            "💾 GPU Memory: 23.8 GB\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpu_count = torch.cuda.device_count()\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    print(f\"🚀 GPU detected: {gpu_name} (Count: {gpu_count})\")\n",
        "    print(f\"💾 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"⚠️  No GPU detected. Please enable GPU in Runtime > Change runtime type > GPU\")\n",
        "    print(\"   The system will still work but with slower performance\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qr4gpK0Bnglr",
        "outputId": "5ecee047-d126-4194-df31-3f81141d162e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 GPU detected: NVIDIA L4 (Count: 1)\n",
            "💾 GPU Memory: 23.8 GB\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpu_count = torch.cuda.device_count()\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    print(f\"🚀 GPU detected: {gpu_name} (Count: {gpu_count})\")\n",
        "    print(f\"💾 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"⚠️  No GPU detected. Please enable GPU in Runtime > Change runtime type > GPU\")\n",
        "    print(\"   The system will still work but with slower performance\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7N1Pmq5nglr"
      },
      "source": [
        "## 🔐 Step 2: Configure Spotify API Credentials\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0pg-9EOvnglr",
        "outputId": "5b12a926-34f5-4cc3-a1f1-f5f328438175",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Environment configured!\n",
            "📱 Spotify Client ID: b2731a573c...\n"
          ]
        }
      ],
      "source": [
        "# Configure Spotify API credentials\n",
        "import os\n",
        "\n",
        "# Get your credentials from https://developer.spotify.com/dashboard\n",
        "# 1. Create a new app\n",
        "# 2. Add redirect URI: https://colab.research.google.com/callback\n",
        "# 3. Copy Client ID and Client Secret here\n",
        "\n",
        "SPOTIFY_CLIENT_ID = \"b2731a573c9c47fa8be846d383294924\"  # Replace with your actual Client ID\n",
        "SPOTIFY_CLIENT_SECRET = \"55f1854cebb9416b85a4c91914974cf0\"  # Replace with your actual Client Secret\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"SPOTIFY_CLIENT_ID\"] = SPOTIFY_CLIENT_ID\n",
        "os.environ[\"SPOTIFY_CLIENT_SECRET\"] = SPOTIFY_CLIENT_SECRET\n",
        "os.environ[\"SPOTIFY_REDIRECT_URI\"] = \"https://colab.research.google.com/callback\"\n",
        "\n",
        "# Colab-specific settings\n",
        "os.environ[\"PYTHONPATH\"] = \"/content/hack-mvp\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"VLLM_HOST\"] = \"0.0.0.0\"\n",
        "os.environ[\"VLLM_PORT\"] = \"8002\"\n",
        "os.environ[\"API_BASE_URL\"] = \"http://localhost:8000\"\n",
        "os.environ[\"FRONTEND_URL\"] = \"http://localhost:8501\"\n",
        "os.environ[\"DATABASE_URL\"] = \"sqlite:///./data/music_app.db\"\n",
        "os.environ[\"MODEL_STORAGE_PATH\"] = \"./models\"\n",
        "os.environ[\"DATA_STORAGE_PATH\"] = \"./data\"\n",
        "\n",
        "print(\"✅ Environment configured!\")\n",
        "print(f\"📱 Spotify Client ID: {SPOTIFY_CLIENT_ID[:10]}...\" if SPOTIFY_CLIENT_ID != \"your_client_id_here\" else \"⚠️  Please update your Spotify credentials above\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KJkt5Uknglr"
      },
      "source": [
        "## 🧠 Step 3: Initialize AI Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Xv46434bnglr",
        "outputId": "216584ad-b3b1-4278-bbd6-7b9304791c31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧠 Initializing neural network models...\n",
            "✅ Neural network models initialized and saved!\n",
            "📊 Model sizes:\n",
            "   Audio Embedding: 25,728 parameters\n",
            "   Bradley-Terry: 6,400,065 parameters\n",
            "   Collaborative Filter: 14,113,025 parameters\n"
          ]
        }
      ],
      "source": [
        "# Initialize neural network models\n",
        "import torch\n",
        "import sys\n",
        "sys.path.append('/content/hack-mvp')\n",
        "\n",
        "from models.neural_networks import MusicEmbeddingNet, BradleyTerryModel, DeepCollaborativeFilter\n",
        "\n",
        "print(\"🧠 Initializing neural network models...\")\n",
        "\n",
        "# Create models\n",
        "audio_model = MusicEmbeddingNet(num_audio_features=13, embedding_dim=128)\n",
        "bt_model = BradleyTerryModel(num_items=100000, embedding_dim=64)\n",
        "cf_model = DeepCollaborativeFilter(num_users=10000, num_items=100000, embedding_dim=128)\n",
        "\n",
        "# Save models\n",
        "torch.save(audio_model.state_dict(), 'models/audio_embedding.pth')\n",
        "torch.save(bt_model.state_dict(), 'models/bradley_terry.pth')\n",
        "torch.save(cf_model.state_dict(), 'models/collaborative_filter.pth')\n",
        "\n",
        "print(\"✅ Neural network models initialized and saved!\")\n",
        "print(f\"📊 Model sizes:\")\n",
        "print(f\"   Audio Embedding: {sum(p.numel() for p in audio_model.parameters()):,} parameters\")\n",
        "print(f\"   Bradley-Terry: {sum(p.numel() for p in bt_model.parameters()):,} parameters\")\n",
        "print(f\"   Collaborative Filter: {sum(p.numel() for p in cf_model.parameters()):,} parameters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a08yGIVEnglr"
      },
      "source": [
        "## 🚀 Step 4: Start All Services\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "p1ZRSEMJnglr",
        "outputId": "54255bbd-edf4-4bd7-eed0-3dc3aca1a0b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Starting Music AI Recommendation System...\n",
            "🧠 Starting vLLM server with GPT-OSS-20B...\n",
            "⚡ Starting FastAPI backend...\n",
            "🖥️  Starting Streamlit frontend...\n",
            "⏳ Services starting... This may take a few minutes for the first run.\n",
            "   - vLLM server: Downloading GPT-OSS-20B model (~2-3 minutes)\n",
            "   - Backend: Starting FastAPI server\n",
            "   - Frontend: Starting Streamlit app\n"
          ]
        }
      ],
      "source": [
        "# Start all services in background\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import requests\n",
        "from google.colab import output\n",
        "\n",
        "print(\"🚀 Starting Music AI Recommendation System...\")\n",
        "\n",
        "# Enable Colab port forwarding\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "def start_vllm_server():\n",
        "    \"\"\"Start vLLM server with GPT-OSS-20B.\"\"\"\n",
        "    print(\"🧠 Starting vLLM server with GPT-OSS-20B...\")\n",
        "    cmd = [\n",
        "        \"python\", \"-m\", \"vllm.entrypoints.api_server\",\n",
        "        \"--model\", \"openai-community/gpt-oss-20b\",\n",
        "        \"--host\", \"0.0.0.0\",\n",
        "        \"--port\", \"8002\",\n",
        "        \"--gpu-memory-utilization\", \"0.8\",\n",
        "        \"--max-model-len\", \"4096\"\n",
        "    ]\n",
        "    subprocess.run(cmd, capture_output=True)\n",
        "\n",
        "def start_backend():\n",
        "    \"\"\"Start FastAPI backend.\"\"\"\n",
        "    print(\"⚡ Starting FastAPI backend...\")\n",
        "    cmd = [\n",
        "        \"python\", \"-m\", \"uvicorn\",\n",
        "        \"backend.main:app\",\n",
        "        \"--host\", \"0.0.0.0\",\n",
        "        \"--port\", \"8000\"\n",
        "    ]\n",
        "    subprocess.run(cmd, capture_output=True)\n",
        "\n",
        "def start_frontend():\n",
        "    \"\"\"Start Streamlit frontend.\"\"\"\n",
        "    print(\"🖥️  Starting Streamlit frontend...\")\n",
        "    cmd = [\n",
        "        \"python\", \"-m\", \"streamlit\", \"run\",\n",
        "        \"frontend/app.py\",\n",
        "        \"--server.port\", \"8501\",\n",
        "        \"--server.address\", \"0.0.0.0\",\n",
        "        \"--server.headless\", \"true\"\n",
        "    ]\n",
        "    subprocess.run(cmd, capture_output=True)\n",
        "\n",
        "# Start services in background threads\n",
        "vllm_thread = threading.Thread(target=start_vllm_server, daemon=True)\n",
        "backend_thread = threading.Thread(target=start_backend, daemon=True)\n",
        "frontend_thread = threading.Thread(target=start_frontend, daemon=True)\n",
        "\n",
        "vllm_thread.start()\n",
        "backend_thread.start()\n",
        "frontend_thread.start()\n",
        "\n",
        "print(\"⏳ Services starting... This may take a few minutes for the first run.\")\n",
        "print(\"   - vLLM server: Downloading GPT-OSS-20B model (~2-3 minutes)\")\n",
        "print(\"   - Backend: Starting FastAPI server\")\n",
        "print(\"   - Frontend: Starting Streamlit app\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ4HfCYmngls"
      },
      "source": [
        "## ⏳ Step 5: Wait for Services to Start\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "30Mf_MDmngls",
        "outputId": "58f69b4d-d300-4734-dc69-99e596d9620d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Waiting for services to start...\n",
            "   This may take 3-5 minutes for the first run (model download)\n",
            "\n",
            "🔄 Attempt 1/20:\n",
            "⏳ Backend API: Still starting... (HTTPConnectionPool(host='localhost', port=8000): M...)\n",
            "⏳ vLLM Server: Still starting... (HTTPConnectionPool(host='localhost', port=8002): M...)\n",
            "✅ Streamlit Frontend: Ready (Status: 200)\n",
            "⏳ Waiting 15 seconds before next attempt...\n",
            "\n",
            "🔄 Attempt 2/20:\n",
            "⏳ Backend API: Still starting... (HTTPConnectionPool(host='localhost', port=8000): M...)\n",
            "⏳ vLLM Server: Still starting... (HTTPConnectionPool(host='localhost', port=8002): M...)\n",
            "✅ Streamlit Frontend: Ready (Status: 200)\n",
            "⏳ Waiting 15 seconds before next attempt...\n",
            "\n",
            "🔄 Attempt 3/20:\n",
            "⏳ Backend API: Still starting... (HTTPConnectionPool(host='localhost', port=8000): M...)\n",
            "⏳ vLLM Server: Still starting... (HTTPConnectionPool(host='localhost', port=8002): M...)\n",
            "✅ Streamlit Frontend: Ready (Status: 200)\n",
            "⏳ Waiting 15 seconds before next attempt...\n",
            "\n",
            "🔄 Attempt 4/20:\n",
            "⏳ Backend API: Still starting... (HTTPConnectionPool(host='localhost', port=8000): M...)\n",
            "⏳ vLLM Server: Still starting... (HTTPConnectionPool(host='localhost', port=8002): M...)\n",
            "✅ Streamlit Frontend: Ready (Status: 200)\n",
            "⏳ Waiting 15 seconds before next attempt...\n",
            "\n",
            "🔄 Attempt 5/20:\n",
            "⏳ Backend API: Still starting... (HTTPConnectionPool(host='localhost', port=8000): M...)\n",
            "⏳ vLLM Server: Still starting... (HTTPConnectionPool(host='localhost', port=8002): M...)\n",
            "✅ Streamlit Frontend: Ready (Status: 200)\n",
            "⏳ Waiting 15 seconds before next attempt...\n",
            "\n",
            "🔄 Attempt 6/20:\n",
            "⏳ Backend API: Still starting... (HTTPConnectionPool(host='localhost', port=8000): M...)\n",
            "⏳ vLLM Server: Still starting... (HTTPConnectionPool(host='localhost', port=8002): M...)\n",
            "✅ Streamlit Frontend: Ready (Status: 200)\n",
            "⏳ Waiting 15 seconds before next attempt...\n",
            "\n",
            "🔄 Attempt 7/20:\n",
            "⏳ Backend API: Still starting... (HTTPConnectionPool(host='localhost', port=8000): M...)\n",
            "⏳ vLLM Server: Still starting... (HTTPConnectionPool(host='localhost', port=8002): M...)\n",
            "✅ Streamlit Frontend: Ready (Status: 200)\n",
            "⏳ Waiting 15 seconds before next attempt...\n",
            "\n",
            "🔄 Attempt 8/20:\n",
            "⏳ Backend API: Still starting... (HTTPConnectionPool(host='localhost', port=8000): M...)\n",
            "⏳ vLLM Server: Still starting... (HTTPConnectionPool(host='localhost', port=8002): M...)\n",
            "✅ Streamlit Frontend: Ready (Status: 200)\n",
            "⏳ Waiting 15 seconds before next attempt...\n",
            "\n",
            "🔄 Attempt 9/20:\n",
            "⏳ Backend API: Still starting... (HTTPConnectionPool(host='localhost', port=8000): M...)\n",
            "⏳ vLLM Server: Still starting... (HTTPConnectionPool(host='localhost', port=8002): M...)\n",
            "✅ Streamlit Frontend: Ready (Status: 200)\n",
            "⏳ Waiting 15 seconds before next attempt...\n",
            "\n",
            "🔄 Attempt 10/20:\n",
            "⏳ Backend API: Still starting... (HTTPConnectionPool(host='localhost', port=8000): M...)\n",
            "⏳ vLLM Server: Still starting... (HTTPConnectionPool(host='localhost', port=8002): M...)\n",
            "✅ Streamlit Frontend: Ready (Status: 200)\n",
            "⏳ Waiting 15 seconds before next attempt...\n",
            "\n",
            "🔄 Attempt 11/20:\n",
            "⏳ Backend API: Still starting... (HTTPConnectionPool(host='localhost', port=8000): M...)\n",
            "⏳ vLLM Server: Still starting... (HTTPConnectionPool(host='localhost', port=8002): M...)\n",
            "✅ Streamlit Frontend: Ready (Status: 200)\n",
            "⏳ Waiting 15 seconds before next attempt...\n",
            "\n",
            "🔄 Attempt 12/20:\n",
            "⏳ Backend API: Still starting... (HTTPConnectionPool(host='localhost', port=8000): M...)\n",
            "⏳ vLLM Server: Still starting... (HTTPConnectionPool(host='localhost', port=8002): M...)\n",
            "✅ Streamlit Frontend: Ready (Status: 200)\n",
            "⏳ Waiting 15 seconds before next attempt...\n",
            "\n",
            "🔄 Attempt 13/20:\n",
            "⏳ Backend API: Still starting... (HTTPConnectionPool(host='localhost', port=8000): M...)\n",
            "⏳ vLLM Server: Still starting... (HTTPConnectionPool(host='localhost', port=8002): M...)\n",
            "✅ Streamlit Frontend: Ready (Status: 200)\n",
            "⏳ Waiting 15 seconds before next attempt...\n",
            "\n",
            "🔄 Attempt 14/20:\n",
            "⏳ Backend API: Still starting... (HTTPConnectionPool(host='localhost', port=8000): M...)\n",
            "⏳ vLLM Server: Still starting... (HTTPConnectionPool(host='localhost', port=8002): M...)\n",
            "✅ Streamlit Frontend: Ready (Status: 200)\n",
            "⏳ Waiting 15 seconds before next attempt...\n",
            "\n",
            "🔄 Attempt 15/20:\n",
            "⏳ Backend API: Still starting... (HTTPConnectionPool(host='localhost', port=8000): M...)\n",
            "⏳ vLLM Server: Still starting... (HTTPConnectionPool(host='localhost', port=8002): M...)\n",
            "✅ Streamlit Frontend: Ready (Status: 200)\n",
            "⏳ Waiting 15 seconds before next attempt...\n",
            "\n",
            "🔄 Attempt 16/20:\n",
            "⏳ Backend API: Still starting... (HTTPConnectionPool(host='localhost', port=8000): M...)\n",
            "⏳ vLLM Server: Still starting... (HTTPConnectionPool(host='localhost', port=8002): M...)\n",
            "✅ Streamlit Frontend: Ready (Status: 200)\n",
            "⏳ Waiting 15 seconds before next attempt...\n",
            "\n",
            "🔄 Attempt 17/20:\n",
            "⏳ Backend API: Still starting... (HTTPConnectionPool(host='localhost', port=8000): M...)\n",
            "⏳ vLLM Server: Still starting... (HTTPConnectionPool(host='localhost', port=8002): M...)\n",
            "✅ Streamlit Frontend: Ready (Status: 200)\n",
            "⏳ Waiting 15 seconds before next attempt...\n",
            "\n",
            "🔄 Attempt 18/20:\n",
            "⏳ Backend API: Still starting... (HTTPConnectionPool(host='localhost', port=8000): M...)\n",
            "⏳ vLLM Server: Still starting... (HTTPConnectionPool(host='localhost', port=8002): M...)\n",
            "✅ Streamlit Frontend: Ready (Status: 200)\n",
            "⏳ Waiting 15 seconds before next attempt...\n",
            "\n",
            "🔄 Attempt 19/20:\n",
            "⏳ Backend API: Still starting... (HTTPConnectionPool(host='localhost', port=8000): M...)\n",
            "⏳ vLLM Server: Still starting... (HTTPConnectionPool(host='localhost', port=8002): M...)\n",
            "✅ Streamlit Frontend: Ready (Status: 200)\n",
            "⏳ Waiting 15 seconds before next attempt...\n",
            "\n",
            "🔄 Attempt 20/20:\n",
            "⏳ Backend API: Still starting... (HTTPConnectionPool(host='localhost', port=8000): M...)\n",
            "⏳ vLLM Server: Still starting... (HTTPConnectionPool(host='localhost', port=8002): M...)\n",
            "✅ Streamlit Frontend: Ready (Status: 200)\n",
            "⏳ Waiting 15 seconds before next attempt...\n",
            "\n",
            "⚠️  Some services may still be starting. You can continue or restart the services.\n"
          ]
        }
      ],
      "source": [
        "# Wait for services to be ready and test them\n",
        "import time\n",
        "import requests\n",
        "\n",
        "print(\"⏳ Waiting for services to start...\")\n",
        "print(\"   This may take 3-5 minutes for the first run (model download)\")\n",
        "\n",
        "# Wait for initial startup\n",
        "time.sleep(30)\n",
        "\n",
        "# Test services\n",
        "def test_service(url, name, timeout=10):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=timeout)\n",
        "        if response.status_code == 200:\n",
        "            print(f\"✅ {name}: Ready (Status: {response.status_code})\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"⚠️  {name}: Status {response.status_code}\")\n",
        "            return False\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"⏳ {name}: Still starting... ({str(e)[:50]}...)\")\n",
        "        return False\n",
        "\n",
        "# Test all services\n",
        "services = [\n",
        "    (\"http://localhost:8000/health\", \"Backend API\"),\n",
        "    (\"http://localhost:8002/health\", \"vLLM Server\"),\n",
        "    (\"http://localhost:8501/_stcore/health\", \"Streamlit Frontend\")\n",
        "]\n",
        "\n",
        "all_ready = False\n",
        "attempts = 0\n",
        "max_attempts = 20\n",
        "\n",
        "while not all_ready and attempts < max_attempts:\n",
        "    attempts += 1\n",
        "    print(f\"\\n🔄 Attempt {attempts}/{max_attempts}:\")\n",
        "\n",
        "    results = []\n",
        "    for url, name in services:\n",
        "        results.append(test_service(url, name))\n",
        "\n",
        "    all_ready = all(results)\n",
        "\n",
        "    if not all_ready:\n",
        "        print(f\"⏳ Waiting 15 seconds before next attempt...\")\n",
        "        time.sleep(15)\n",
        "\n",
        "if all_ready:\n",
        "    print(\"\\n🎉 All services are ready!\")\n",
        "else:\n",
        "    print(\"\\n⚠️  Some services may still be starting. You can continue or restart the services.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gv5ccNrngls"
      },
      "source": [
        "## 🎵 Step 6: Access Your Music AI App\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1SDS83U9ngls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3b7b8ce-0407-4990-f47e-bdff1c180c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉 Music AI Recommendation System is now running!\n",
            "\n",
            "📱 Access your application:\n",
            "\n",
            "🖥️  Frontend (Streamlit App):\n",
            "   The Streamlit app should be embedded below or accessible through Colab's interface\n",
            "   📱 App is running on http://localhost:8501\n",
            "\n",
            "⚡ Backend API:\n",
            "   http://localhost:8000\n",
            "\n",
            "📚 API Documentation:\n",
            "   http://localhost:8000/docs\n",
            "\n",
            "🧠 vLLM Server (GPT-OSS-20B):\n",
            "   http://localhost:8002\n",
            "\n",
            "🎯 What you can do:\n",
            "   1. 🔐 Authenticate with Spotify\n",
            "   2. 🎵 Get AI-powered music recommendations\n",
            "   3. 🎯 Train the AI with A/B comparisons\n",
            "   4. 👤 View your musical taste profile\n",
            "   5. 📊 Explore analytics and insights\n"
          ]
        }
      ],
      "source": [
        "# Display access information\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "print(\"🎉 Music AI Recommendation System is now running!\")\n",
        "print(\"\\n📱 Access your application:\")\n",
        "print(\"\\n🖥️  Frontend (Streamlit App):\")\n",
        "print(\"   The Streamlit app should be embedded below or accessible through Colab's interface\")\n",
        "\n",
        "# Try to embed the Streamlit app\n",
        "try:\n",
        "    from google.colab import output\n",
        "    output.serve_kernel_port_as_iframe(8501, path='/', anchor_text='🎵 Open Music AI App')\n",
        "    print(\"   ✅ Click the link above to open the app!\")\n",
        "except:\n",
        "    print(\"   📱 App is running on http://localhost:8501\")\n",
        "\n",
        "print(\"\\n⚡ Backend API:\")\n",
        "print(\"   http://localhost:8000\")\n",
        "print(\"\\n📚 API Documentation:\")\n",
        "print(\"   http://localhost:8000/docs\")\n",
        "\n",
        "print(\"\\n🧠 vLLM Server (GPT-OSS-20B):\")\n",
        "print(\"   http://localhost:8002\")\n",
        "\n",
        "print(\"\\n🎯 What you can do:\")\n",
        "print(\"   1. 🔐 Authenticate with Spotify\")\n",
        "print(\"   2. 🎵 Get AI-powered music recommendations\")\n",
        "print(\"   3. 🎯 Train the AI with A/B comparisons\")\n",
        "print(\"   4. 👤 View your musical taste profile\")\n",
        "print(\"   5. 📊 Explore analytics and insights\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN3WeArJngls"
      },
      "source": [
        "## 🎮 Step 7: Interactive Demo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "o65ncFmKngls",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0f97d3e1be0045b8883b5102cdc7511c",
            "85f30e565e35429f9836b00cabe26fc5",
            "e3417079987946709f71e21501fd45df",
            "b6471c3c29724f85939b1a9f2b6effb9"
          ]
        },
        "outputId": "3769f8ef-d093-4884-c766-b16f5798b3bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎮 Running interactive demo...\n",
            "   This showcases all the features of the Music AI system\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m╭──────────────────────────────────────────╮\u001b[0m\n",
              "\u001b[1;34m│\u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m🎵 AI Music Recommendation System\u001b[0m\u001b[1;34m       \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m│\u001b[0m\n",
              "\u001b[1;34m│\u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34mPowered by GPT-OSS-20B & Neural Networks\u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m│\u001b[0m\n",
              "\u001b[1;34m│\u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34mOpenAI Hackathon 2025\u001b[0m\u001b[1;34m                   \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m│\u001b[0m\n",
              "\u001b[1;34m╰──────────────────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">╭──────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">│ 🎵 AI Music Recommendation System        │</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">│ Powered by GPT-OSS-20B &amp; Neural Networks │</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">│ OpenAI Hackathon 2025                    │</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">╰──────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;36m1\u001b[0m\u001b[1m. 🔐 Spotify Authentication & Personal Data Access\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">. 🔐 Spotify Authentication &amp; Personal Data Access</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f97d3e1be0045b8883b5102cdc7511c"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m         Sample User Playlists         \u001b[0m\n",
              "┏━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mPlaylist     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTracks\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mAvg Energy\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36mMorning Vibes\u001b[0m\u001b[36m \u001b[0m│     47 │\u001b[32m \u001b[0m\u001b[32m      0.73\u001b[0m\u001b[32m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mWorkout Hits \u001b[0m\u001b[36m \u001b[0m│     32 │\u001b[32m \u001b[0m\u001b[32m      0.91\u001b[0m\u001b[32m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mChill Evening\u001b[0m\u001b[36m \u001b[0m│     28 │\u001b[32m \u001b[0m\u001b[32m      0.42\u001b[0m\u001b[32m \u001b[0m│\n",
              "└───────────────┴────────┴────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">         Sample User Playlists         </span>\n",
              "┏━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Playlist      </span>┃<span style=\"font-weight: bold\"> Tracks </span>┃<span style=\"font-weight: bold\"> Avg Energy </span>┃\n",
              "┡━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Morning Vibes </span>│     47 │<span style=\"color: #008000; text-decoration-color: #008000\">       0.73 </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Workout Hits  </span>│     32 │<span style=\"color: #008000; text-decoration-color: #008000\">       0.91 </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Chill Evening </span>│     28 │<span style=\"color: #008000; text-decoration-color: #008000\">       0.42 </span>│\n",
              "└───────────────┴────────┴────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;36m2\u001b[0m\u001b[1m. 🧠 AI-Powered Music Recommendations\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">. 🧠 AI-Powered Music Recommendations</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "🎯 Generating recommendations using multiple AI approaches:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🎯 Generating recommendations using multiple AI approaches:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   • Neural Collaborative Filtering\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   • Neural Collaborative Filtering\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   • Audio Similarity Embeddings\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   • Audio Similarity Embeddings\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   • RLHF Preference Learning\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   • RLHF Preference Learning\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                                         AI Recommendations                                         \u001b[0m\n",
              "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mTrack     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mArtist        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mAI Confidence\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mMatch Reason                                      \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36mLevitating\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mDua Lipa      \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m         0.94\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mHigh energy pop matching your dance preferences   \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mGood 4 U  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mOlivia Rodrigo\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m         0.87\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mSimilar vocal style and emotional intensity       \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mStay      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mThe Kid LAROI \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m         0.82\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mMatches your preference for modern pop-rock fusion\u001b[0m\u001b[33m \u001b[0m│\n",
              "└────────────┴────────────────┴───────────────┴────────────────────────────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                         AI Recommendations                                         </span>\n",
              "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Track      </span>┃<span style=\"font-weight: bold\"> Artist         </span>┃<span style=\"font-weight: bold\"> AI Confidence </span>┃<span style=\"font-weight: bold\"> Match Reason                                       </span>┃\n",
              "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Levitating </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Dua Lipa       </span>│<span style=\"color: #008000; text-decoration-color: #008000\">          0.94 </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> High energy pop matching your dance preferences    </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Good 4 U   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Olivia Rodrigo </span>│<span style=\"color: #008000; text-decoration-color: #008000\">          0.87 </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> Similar vocal style and emotional intensity        </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Stay       </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> The Kid LAROI  </span>│<span style=\"color: #008000; text-decoration-color: #008000\">          0.82 </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> Matches your preference for modern pop-rock fusion </span>│\n",
              "└────────────┴────────────────┴───────────────┴────────────────────────────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;36m3\u001b[0m\u001b[1m. 🎯 Reinforcement Learning from Human Feedback\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">. 🎯 Reinforcement Learning from Human Feedback</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "👤 User makes preference comparisons:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">👤 User makes preference comparisons:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "╭──────────────────────────────────────────── A/B Preference Learning ────────────────────────────────────────────╮\n",
              "│ Track A: 'Blinding Lights' vs Track B: 'Watermelon Sugar'                                                       │\n",
              "│ User chooses: Track A ✅                                                                                        │\n",
              "│                                                                                                                 │\n",
              "│ 🧠 Bradley-Terry model updates item strengths...                                                                │\n",
              "│ 📈 Preference accuracy improved: 73% → 78%                                                                      │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────────── A/B Preference Learning ────────────────────────────────────────────╮\n",
              "│ Track A: 'Blinding Lights' vs Track B: 'Watermelon Sugar'                                                       │\n",
              "│ User chooses: Track A ✅                                                                                        │\n",
              "│                                                                                                                 │\n",
              "│ 🧠 Bradley-Terry model updates item strengths...                                                                │\n",
              "│ 📈 Preference accuracy improved: 73% → 78%                                                                      │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "📊 RLHF Training Progress:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">📊 RLHF Training Progress:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6471c3c29724f85939b1a9f2b6effb9"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;36m4\u001b[0m\u001b[1m. 🤖 GPT-OSS-20B Reasoning & Explanations\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">. 🤖 GPT-OSS-20B Reasoning &amp; Explanations</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "💭 AI generates natural language explanations:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">💭 AI generates natural language explanations:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[34m╭─\u001b[0m\u001b[34m────────────────────────────────────────\u001b[0m\u001b[34m 🎵 Heat Waves - Glass Animals \u001b[0m\u001b[34m────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
              "\u001b[34m│\u001b[0m This track perfectly matches your love for indie pop with dreamy synths. The moderate tempo and introspective   \u001b[34m│\u001b[0m\n",
              "\u001b[34m│\u001b[0m lyrics align with your evening listening patterns, while the unique production style reflects your preference   \u001b[34m│\u001b[0m\n",
              "\u001b[34m│\u001b[0m for artistic creativity over mainstream polish.                                                                 \u001b[34m│\u001b[0m\n",
              "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭───────────────────────────────────────── 🎵 Heat Waves - Glass Animals ─────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> This track perfectly matches your love for indie pop with dreamy synths. The moderate tempo and introspective   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> lyrics align with your evening listening patterns, while the unique production style reflects your preference   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> for artistic creativity over mainstream polish.                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[34m╭─\u001b[0m\u001b[34m────────────────────────────────────────\u001b[0m\u001b[34m 🎵 Industry Baby - Lil Nas X \u001b[0m\u001b[34m─────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
              "\u001b[34m│\u001b[0m Based on your hip-hop preferences and high-energy workout selections, this track combines catchy hooks with     \u001b[34m│\u001b[0m\n",
              "\u001b[34m│\u001b[0m confident delivery. The production quality and mainstream appeal match songs you've previously rated highly.    \u001b[34m│\u001b[0m\n",
              "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭───────────────────────────────────────── 🎵 Industry Baby - Lil Nas X ──────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Based on your hip-hop preferences and high-energy workout selections, this track combines catchy hooks with     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> confident delivery. The production quality and mainstream appeal match songs you've previously rated highly.    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;36m5\u001b[0m\u001b[1m. 🔄 Continuous Learning & Adaptation\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">. 🔄 Continuous Learning &amp; Adaptation</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                            AI Learning Progress                            \u001b[0m\n",
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mMetric                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mBefore Training\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mAfter Training\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mImprovement\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36mRecommendation Accuracy\u001b[0m\u001b[36m \u001b[0m│             67% │\u001b[32m \u001b[0m\u001b[32m           84%\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m       +17%\u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mUser Satisfaction      \u001b[0m\u001b[36m \u001b[0m│           3.2/5 │\u001b[32m \u001b[0m\u001b[32m         4.1/5\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m       +28%\u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mPlaylist Match Score   \u001b[0m\u001b[36m \u001b[0m│            0.73 │\u001b[32m \u001b[0m\u001b[32m          0.89\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m       +22%\u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mExplanation Quality    \u001b[0m\u001b[36m \u001b[0m│           3.5/5 │\u001b[32m \u001b[0m\u001b[32m         4.3/5\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m       +23%\u001b[0m\u001b[33m \u001b[0m│\n",
              "└─────────────────────────┴─────────────────┴────────────────┴─────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                            AI Learning Progress                            </span>\n",
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Metric                  </span>┃<span style=\"font-weight: bold\"> Before Training </span>┃<span style=\"font-weight: bold\"> After Training </span>┃<span style=\"font-weight: bold\"> Improvement </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Recommendation Accuracy </span>│             67% │<span style=\"color: #008000; text-decoration-color: #008000\">            84% </span>│<span style=\"color: #808000; text-decoration-color: #808000\">        +17% </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> User Satisfaction       </span>│           3.2/5 │<span style=\"color: #008000; text-decoration-color: #008000\">          4.1/5 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">        +28% </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Playlist Match Score    </span>│            0.73 │<span style=\"color: #008000; text-decoration-color: #008000\">           0.89 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">        +22% </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Explanation Quality     </span>│           3.5/5 │<span style=\"color: #008000; text-decoration-color: #008000\">          4.3/5 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">        +23% </span>│\n",
              "└─────────────────────────┴─────────────────┴────────────────┴─────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "✨ The AI continuously improves with each user interaction!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "✨ The AI continuously improves with each user interaction!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;32m╭─────────────────────────────────────────────────────────────────────────╮\u001b[0m\n",
              "\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m🏆 Demo Complete!\u001b[0m\u001b[1;32m                                                      \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\n",
              "\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mThis showcases creative use of GPT-OSS-20B for music understanding\u001b[0m\u001b[1;32m     \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\n",
              "\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mCombined with neural networks and RLHF for personalized recommendations\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\n",
              "\u001b[1;32m╰─────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">╭─────────────────────────────────────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 🏆 Demo Complete!                                                       │</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ This showcases creative use of GPT-OSS-20B for music understanding      │</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ Combined with neural networks and RLHF for personalized recommendations │</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">╰─────────────────────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Run the interactive demo\n",
        "import asyncio\n",
        "import sys\n",
        "sys.path.append('/content/hack-mvp')\n",
        "\n",
        "from demo.showcase import HackathonDemo\n",
        "\n",
        "print(\"🎮 Running interactive demo...\")\n",
        "print(\"   This showcases all the features of the Music AI system\")\n",
        "\n",
        "demo = HackathonDemo()\n",
        "await demo.run_full_demo()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlLFlqOEngls"
      },
      "source": [
        "## 🎉 Congratulations!\n",
        "\n",
        "You've successfully set up and running the **AI Music Recommendation System** with:\n",
        "\n",
        "- ✅ **GPT-OSS-20B** for natural language explanations\n",
        "- ✅ **Neural Networks** for personalized recommendations\n",
        "- ✅ **RLHF Training** with interactive A/B comparisons\n",
        "- ✅ **Spotify Integration** with OAuth authentication\n",
        "- ✅ **Real-time Learning** from user feedback\n",
        "- ✅ **Beautiful UI** with analytics and insights\n",
        "\n",
        "### 🎯 Next Steps:\n",
        "1. **Authenticate with Spotify** in the app\n",
        "2. **Get AI recommendations** for your playlists\n",
        "3. **Train the AI** using A/B comparisons\n",
        "4. **Explore your musical taste profile**\n",
        "5. **Share your experience** with others!\n",
        "\n",
        "### 🚀 Deploy to Production:\n",
        "- Use the Docker setup for cloud deployment\n",
        "- Scale with multiple GPU instances\n",
        "- Add more AI models and features\n",
        "\n",
        "**Enjoy your AI-powered music discovery! 🎵**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f97d3e1be0045b8883b5102cdc7511c": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_85f30e565e35429f9836b00cabe26fc5",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Authenticating... \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:02\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Authenticating... <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:02</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "85f30e565e35429f9836b00cabe26fc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3417079987946709f71e21501fd45df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6471c3c29724f85939b1a9f2b6effb9": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_e3417079987946709f71e21501fd45df",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Learning preferences... \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:02\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Learning preferences... <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:02</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}